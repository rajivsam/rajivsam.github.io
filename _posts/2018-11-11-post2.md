---
layout: post
title: Timeseries Analysis of Household Power Consumption
tags:
- News
- Tags
- Blog
- Post
---

<style type="text/css">
	p { text-align: justify; }
</style>
<p>I wanted to try to use PCA to extract the independent components of variation in large time series data. To this end, I used the <a href="https://archive.ics.uci.edu/ml/datasets/individual+household+electric+power+consumption"> household power consumption dataset </a> that provides voltage measurements at one minute intervals over a four year period. In the raw form, this dataset is big. About 2 million instances. This data is dirty. It has missing data - there are about 82 days where data is missing for some portion of the day. So conventional auto-regressive models cannot be applied directly to the entire dataset. However, that is material for another day. A plot of the rolling mean of the voltage values using a 15 day (bi-monthly) window is shown below. Clearly, seaosonal patterns are evident.</p>
<figure >
  <img src="../static/img/rolling_mean_voltage.png" alt="The Pulpit Rock" align="middle" width = "60%">
</figure> 
<p>To analyze independent patterns of variation over this four year period. This is a typical exploratory question. I aggregated data at hourly intervals. A day is represented by a 24 hour vector. Each component of this vector represents the hourly mean voltage for that period. A sample of the dataset is shown below:</p>

<figure >
  <img src="../static/img/day_uhv.png" alt="The Pulpit Rock" align="middle" width = "100%">
</figure> 

In about 5 principal components we can explain the mean hourly variations of voltage in this dataset


<figure >
  <img src="../static/img/exp_var_hpc_pca.png" alt="The Pulpit Rock" align="middle" width = "100%">
</figure>

<p>The first two principal components are shown below. These two components represent major variations in hourly mean voltage over this period.</p>

<figure >
  <img src="../static/img/hourly_pca_1_2.png" alt="The Pulpit Rock" align="middle" width = "100%">
</figure>

<p>A point that stands out to me is that the questions we want to explore on big data often translate to datasets that are not big. In this particular example, I set out trying to characterize the independent components of variation by representing a day by 24 hour vector. We could use finer granularity, for example 30 minute periods or even 15 minute periods. When we use such a representation, the dataset is much more amenable for analysis. So a dataset that is massive in the raw form need not translate to a big dataset for machine learning. The analysis questions and the representations used influence the size of the dataset used for learning.</p>