---
layout: layout
title: Bio
---

<div = "bio_container", style="margin:75px; text-align:justify;">
 <h3>Career Summary</h3>
My career has revolved around data centric software development. I have developed solutions for various application domains, for about two decades. I have donned different hats during this time - software developer, requirements analyst, project manager, architect etc.. Somewhere along the way, the interest in data became passion and I decided to pursue a PhD in machine learning. I have worked extensively with data engineering teams and a variety of stake holders. I have had continuous practice at mapping business requirements to technical development tasks. I have <a href="http://linkedin.com/in/{{ site.linkedin }}">worked </a> in transportation, financial services, retail, telecommunication and the government domains, for both large and small companies.


<h3> My Research</h3>
My research focusses on the problems I encountered over my work experience. For my PhD I have  <a href="{{ site.baseurl }}projects.html">investigated </a> some computational approaches to performing machine learning on big datasets. I have used the following approaches in my research:
<ul style="align:center; margin-left:25px">
  <li>Ensemble Learning</li>
  <li>Divide and Conquer</li>
  <li>Bayesian Online Learning</li>
</ul>
I am interested in developing practical machine learning algorithms for big datasets that occur in business or engineering applications. If you are interested in collaboration or consulting, please get in <a href="mailto:rajiv.sambasivan@gmail.com">touch</a>.

<h3> Tools I Use</h3>

<style>
table {
    font-family: arial, sans-serif;
    border-collapse: collapse;
    width: 80%;
    margin-left: 25px
}

td, th {
    border: 1px solid #dddddd;
    text-align: left;
    padding: 8px;
}

tr:nth-child(even) {
    background-color: #dddddd;
}
</style>


<table>
  <tr>
    <th>Task</th>
    <th>Tools</th>
  </tr>
  <tr>
    <td>Query, shape, wrangle datasets that fit in memory</td>
    <td> Pandas</td>
  </tr>
  <tr>
    <td>Query, shape, wrangle large datasets</td>
    <td>Spark and Dask. If I am forced to, then Hive</td>
  </tr>
  <tr>
    <td>Statistical Analysis</td>
    <td>R</td>
  </tr>
   <tr>
    <td>Time Series</td>
    <td>forecast and Prophet</td>
  </tr>
  <tr>
    <td>Visualization and Dashboarding</td>
    <td>Seaborn, Dash and holoviews </td>
  </tr>
    <tr>
    <td>Machine Learning where I am not working with the optimization component directly</td>
    <td>sklearn, scipy</td>
  </tr>
  <tr>
    <td>Machine Learning where I am working with the optimization component directly</td>
    <td>Tensorflow, pytorch, keras, autograd</td>
  </tr>
   <tr>
    <td>Tools that have my attention recently</td>
    <td>Starspace, Fasttext, FAISS, the mdp-toolkit</td>
  </tr>

</table>
 
</div>
